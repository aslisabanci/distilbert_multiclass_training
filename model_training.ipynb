{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Template Model Development Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The instructions in this notebook will guide you to setup your ML project, and help you connect the pieces together for the automated deployment workflow between this ML repository and Algorithmia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Train, evaluate and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((79, 6), (71, 6))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    X, y = make_classification(\n",
    "        n_samples=1000, n_features=10, class_sep=0.1, random_state=42\n",
    "    )\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=0\n",
    "    )\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=10, max_depth=8, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    rfc_predict = clf.predict(X_test)\n",
    "\n",
    "    confuseds = []\n",
    "    confuseds_y = []\n",
    "    confidents = []\n",
    "\n",
    "    raw_proba = clf.predict_proba(X_test)\n",
    "    probs = raw_proba[:, 0]\n",
    "    not_confident = 0\n",
    "    for i in range(X_test.shape[0]):\n",
    "        proba = probs[i]\n",
    "        if proba > 0.40 and proba < 0.6:\n",
    "            confuseds.append(X_test[i])\n",
    "            confuseds_y.append(y_test[i])\n",
    "            not_confident += 1\n",
    "        else:\n",
    "            confidents.append(X_test[i])\n",
    "    print(f\"not confident: {not_confident}\")\n",
    "\n",
    "    np_confidents = np.array(confidents)\n",
    "    np_confuseds = np.array(confuseds)\n",
    "    np_confuseds_y = np.array(confuseds_y)\n",
    "\n",
    "    raw_proba = clf.predict_proba(confidents)\n",
    "    probs = raw_proba[:, 0]\n",
    "    not_confident = 0\n",
    "    for i in range(len(confidents)):\n",
    "        proba = probs[i]\n",
    "        if proba > 0.40 and proba < 0.6:\n",
    "            not_confident += 1\n",
    "    print(f\"not confident: {not_confident}\")\n",
    "\n",
    "    X_train = np.concatenate((X_train, np_confuseds))\n",
    "    y_train = np.concatenate((y_train, np_confuseds_y))\n",
    "    clf = RandomForestClassifier(n_estimators=10, max_depth=8, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    rfc_predict = clf.predict(X_test)\n",
    "\n",
    "    raw_proba = clf.predict_proba(X_test)\n",
    "    probs = raw_proba[:, 0]\n",
    "    for i in range(X_test.shape[0]):\n",
    "        proba = probs[i]\n",
    "        if proba > 0.40 and proba < 0.6:\n",
    "            not_confident += 1\n",
    "        else:\n",
    "            confidents.append(X_test[i])\n",
    "    print(f\"not confident: {not_confident}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Saving model object to a file\n",
    "When your model is ready, save it locally. Expected model file name by the Github Action is **`model.pkl`** by default. If your model file is named differently, make sure to put it in your **`./github/workflows/algorithmia_deploy.yml`** \n",
    "\n",
    "You do not need to check-in your model file to this repository. During the workflow, this notebook will be executed on a Github worker machine and the resulting model file will be uploaded to Algorithmia by our Github Action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(model, \"model.pkl\", compress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Testing serving (Algorithm) code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run  synthetic_binaryclassifier/src/synthetic_binaryclassifier.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final checks before committing this notebook\n",
    "\n",
    "- Once you are happy with your tests, you can remove the **`if __name__ == \"__main__\"`** snippet from your algorithm script. Remember that all of its contents will be pushed to Algorithmia. Don't stress though, you can always edit!\n",
    "\n",
    "- Make sure that you do not commit/push your Algorithmia API Key!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
